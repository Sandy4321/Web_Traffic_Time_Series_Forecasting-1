{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle competition\n",
    "# Web Traffic Time Series Forecasting\n",
    "# https://www.kaggle.com/c/web-traffic-time-series-forecasting\n",
    "\n",
    "It uses an PROPHET model to predict pages visualisation\n",
    "it takes the key_2 file from the Kaggle competition page with the pages,\n",
    "and dates for each page, to predict, and use the train_2 file as\n",
    "training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas\n",
    "import time\n",
    "from pandas import datetime\n",
    "from fbprophet import Prophet\n",
    "import numpy as np\n",
    "\n",
    "# Set pandas not to cut long strings\n",
    "pandas.set_option(\"display.max_colwidth\",10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keys for output dataframe to submit\n",
    "dataframe_keys = pandas.read_csv('key_2.csv')\n",
    "\n",
    "# Import train data for output dataframe to submit\n",
    "dataframe_train = pandas.read_csv('train_2.csv')\n",
    "dataframe_train = dataframe_train.fillna(0)\n",
    "print(dataframe_keys.head(3))\n",
    "print(dataframe_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manimulate keys dataframe to prepare for predictions and extract dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a column of zeros as initial prediction of the visits for each key \n",
    "dataframe_keys['Visits'] = np.zeros(dataframe_keys.shape[0])\n",
    "\n",
    "# Scrapping the date from the page column in the keys dataframe\n",
    "dataframe_keys['Page'] = dataframe_keys['Page'].apply(lambda x: x.split('-')[:-2])\n",
    "dataframe_keys['Page'] = dataframe_keys['Page'].str.join('-')\n",
    "dataframe_keys['Page'] = dataframe_keys['Page'].apply(lambda x: x.split('_')[:-1])\n",
    "dataframe_keys['Page'] = dataframe_keys['Page'].str.join('_')\n",
    "\n",
    "# Create a list called \"indices\" with all the pages to be predicted\n",
    "# And the corresponding indices in the dataframe\n",
    "indices = dataframe_keys.groupby('Page').apply(lambda x: x.index.tolist())\n",
    "print(dataframe_keys.head())\n",
    "print(indices[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loops over all pages to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(save_pages,ipage,startg,start,dataframe_keys):\n",
    "    if ipage % save_pages == 0:\n",
    "        print('Predicted %1.f pages:' % ipage)\n",
    "        deltatg = time.time()-startg\n",
    "        print('Total time elapsed: %.2f (sec)'% deltatg)\n",
    "        deltat = time.time()-start\n",
    "        print('Time elapsed last %d pages: %.2f (sec)'% (save_pages,deltat))\n",
    "        print('Writing predictions')\n",
    "        header_to_print = ['Id','Visits']\n",
    "        dataframe_keys.to_csv('output.csv', columns=header_to_print, index=False)\n",
    "        print('Predictions written')\n",
    "        print()\n",
    "        start = time.time()\n",
    "    return start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set every how many pages the results are saved on disk\n",
    "save_pages = 10\n",
    "\n",
    "\n",
    "# Calculate the global time from beginning of predictions\n",
    "startg = time.time()\n",
    "# Calculate how much time it takes to predict\n",
    "# save_pages number of pages\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# Make predictions only on the first 100 pages\n",
    "# to check if the loop works\n",
    "for ipage in range(21):\n",
    "#for ipage in range(len(dataframe_train)):\n",
    "    page_to_predict = dataframe_train.iloc[[ipage]]\n",
    "    page_name = page_to_predict.Page.values[0]\n",
    "\n",
    "    indices_page = indices.loc[page_name]\n",
    "    page_to_predict = page_to_predict.drop(['Page'], axis=1)\n",
    "    # prepare dataframe for Prophet\n",
    "    df = pandas.DataFrame()\n",
    "    df['ds'] = list(page_to_predict.columns)\n",
    "    df['y']  = page_to_predict.values[0]\n",
    "    df['ds'] = pandas.to_datetime(df['ds'])\n",
    "    \n",
    "    # Make predictions (initialize predictions with mean)\n",
    "    predictions = np.mean(df.y.mean())*np.ones(len(indices_page))\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        # Set the model to be Prophet\n",
    "        m = Prophet(daily_seasonality=True)\n",
    "        m.fit(df)\n",
    "        future = m.make_future_dataframe(periods=len(indices_page))\n",
    "        forecast = m.predict(future)\n",
    "        predictions = forecast.yhat.values[-len(indices_page):]\n",
    "\n",
    "    print('Predicted page # %1.f:' % ipage,page_name)\n",
    "    for ipred in range(len(indices_page)):\n",
    "        dataframe_keys.set_value(indices_page[ipred],'Visits',predictions[ipred])\n",
    "\n",
    "    # writes the predictions after save_pages number of pages\n",
    "    # returns the start time to calculate how long it takes\n",
    "    # to predict save_pages number of pages\n",
    "    start = write_predictions(save_pages,ipage,startg,start,dataframe_keys)\n",
    "        \n",
    "      \n",
    "print('Save last chunk of predictions')\n",
    "header_to_print = ['Id','Visits']\n",
    "dataframe_keys.to_csv('output.csv', columns=header_to_print, index=False)\n",
    "print('Predictions written')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
